{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rakuten_py_NLP_DL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMzIH2y6nE6nZ6Q6NkWqSTE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ragdehl/Rakuten_py/blob/main/edgar/Rakuten_py_NLP_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAD6OuIKFzKO"
      },
      "source": [
        "# DEEP LEARNING TEXT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scMc7Je3GEQc"
      },
      "source": [
        "Import libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySYaMINIFfu2"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        " \n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1J6h3twGJ5e"
      },
      "source": [
        "Récuperer les données:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2DcZYNjAigc",
        "outputId": "392ebee2-380f-42e5-8ed1-72f90ab4ef37"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cnl7nzsZAMvR",
        "outputId": "cc7c7de7-0cf9-4492-ba01-e96151768da0"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voQEp-WCGN_J"
      },
      "source": [
        "# Initialiser la variable des mots vides\n",
        "stop_words = set(stopwords.words('french'))\n",
        " \n",
        "df_X = pd.read_csv('/content/drive/My Drive/Rakuten/X_train_update.csv',index_col=0)\n",
        "df_y = pd.read_csv('/content/drive/My Drive/Rakuten/Y_train_CVw08PX.csv',index_col=0)\n",
        " \n",
        "#df_X = pd.read_csv(r'C:\\Users\\Edgar\\Documents\\Rakuten\\X_train_update.csv')\n",
        "#df_y = pd.read_csv(r'C:\\Users\\Edgar\\Documents\\Rakuten\\Y_train_CVw08PX.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU3ulrb2Agt6"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        " \n",
        "def lemma(sentence): #Lemmatizer\n",
        "    doc = word_tokenize(sentence, language='french')\n",
        "    return [lemmatizer.lemmatize(token) for token in doc]\n",
        " \n",
        "def stop_words_filetring(mots) : \n",
        "    tokens = []\n",
        "    for mot in mots:\n",
        "        if mot not in stop_words:\n",
        "            tokens.append(mot)\n",
        "    return tokens\n",
        " \n",
        "def clean_text(text):\n",
        "    string = ''\n",
        "    words = word_tokenize(text.lower(), language='french')\n",
        "    for word in words:\n",
        "        if word not in stop_words:\n",
        "            #if word.isascii(): #and word.isalpha():\n",
        "            string += lemmatizer.lemmatize(word) + ' '\n",
        "    return string"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKC8kNTnAheK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fe9f180-dffb-4523-e55c-98cc17f77c31"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF0_tU-IAp3b"
      },
      "source": [
        "On netoye un peu le texte:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLj-_ra_Adiw",
        "outputId": "f08d1b8c-3ab3-4355-c26f-9b5bc6df5a1e"
      },
      "source": [
        "X = df_X.designation.astype(str) + ' ' + df_X.description.astype(str)\n",
        "y = df_y.prdtypecode\n",
        " \n",
        "X_clean = X.apply(lambda cell: clean_text(cell))\n",
        "X_clean"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        olivia : personalisiertes notizbuch / 150 seit...\n",
              "1        journal art ( ) n° 133 28/09/2001 - l'art marc...\n",
              "2        grand stylet ergonomique bleu gamepad nintendo...\n",
              "3        peluche donald - europe - disneyland 2000 ( ma...\n",
              "4        guerre tuques luc a id & eacute ; grandeur . v...\n",
              "                               ...                        \n",
              "84911                     the sims [ import anglais ] nan \n",
              "84912    kit piscine acier nevada déco pierre ø 3.50m x...\n",
              "84913    journal officiel republique francaise n° 46 15...\n",
              "84914    table basse bois récupération massif base blan...\n",
              "84915    gomme collection 2 gommes pinguin glace vert o...\n",
              "Length: 84916, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNF_asbzAyEO"
      },
      "source": [
        "Combien de mots uniques?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMJmfVL1Axfo",
        "outputId": "f2450c6a-429e-4e4e-a2d7-c641c90c6f92"
      },
      "source": [
        "lis = []\n",
        "for element in X_clean.str.split():\n",
        "    for word in element:\n",
        "        lis.append(word)\n",
        "\n",
        "len(list(set(lis)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235642"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0yJKWitdzTD"
      },
      "source": [
        "Transformer les categories en numeros de 0 à 26"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qGeldE_d-Hu",
        "outputId": "f77ad9dc-07ec-4ad7-d0cd-3d440cdc3374"
      },
      "source": [
        "categories = list(set(y.to_list()))\n",
        "y_trans = y\n",
        "i = 0\n",
        "for category in categories:\n",
        "    y_trans = y_trans.replace(category,i)\n",
        "    i+=1\n",
        "\n",
        "y_trans"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         4\n",
              "1        25\n",
              "2        20\n",
              "3         0\n",
              "4         6\n",
              "         ..\n",
              "84911    17\n",
              "84912    10\n",
              "84913    25\n",
              "84914    11\n",
              "84915    23\n",
              "Name: prdtypecode, Length: 84916, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XANmHVOod_o8"
      },
      "source": [
        "Separer en train et test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vupRMm2eBBI8"
      },
      "source": [
        "# Importer la classe train_test \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Séparer le jeu de données en données d'entraînement et données test \n",
        "X_train, X_test, y_train, y_test = train_test_split(X_clean, y_trans.astype(str),train_size = 0.1, test_size=0.02)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35-abcuydLB3"
      },
      "source": [
        "Vectoriser avec TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo9miGdRA4oP"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfid = TfidfVectorizer(analyzer='word',\n",
        "                  tokenizer=word_tokenize,\n",
        "                      #strip_accents='unicode',\n",
        "                      #stop_words=french_stop_words_no_accent, # peut etre interessant parce que lisse la progression\n",
        "                  max_df=0.8,\n",
        "                  min_df=2,\n",
        "                  ngram_range=(1,2),\n",
        "                  use_idf=True,\n",
        "                  smooth_idf=True,\n",
        "                  sublinear_tf=False,\n",
        "                  binary=True,\n",
        "                  )\n",
        "\n",
        "X_train_trans = tfid.fit_transform(X_train)\n",
        "X_test_trans = tfid.transform(X_test)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTt6WTmLH-9r"
      },
      "source": [
        "X_train_trans = X_train_trans.todense()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxVl0O-8IDT4"
      },
      "source": [
        "X_test_trans = X_test_trans.todense()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjcLY6cGYuAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caab3644-c6bf-42d4-c7a4-9c9667447f33"
      },
      "source": [
        "input_dim = X_train_trans.shape[1]\n",
        "input_dim"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80805"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6W221lubf9W"
      },
      "source": [
        "Vectoriser avec Countvectorizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VequlYCDbkB4"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialiser un objet vectorisateur\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Mettre à jour la valeur de X_train et X_test\n",
        "cv = vectorizer.fit(X_train)\n",
        "\n",
        "X_train_trans = cv.transform(X_train).todense()\n",
        "X_test_trans = cv.transform(X_test).todense()\n",
        "\n",
        "input_dim = X_train_trans.shape[1]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nordwxChBpul"
      },
      "source": [
        "Deep Learning:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgDV0kRmBo8c"
      },
      "source": [
        "#vectorize the labels\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "one_hot_train_labels = to_categorical(y_train)\n",
        "one_hot_test_labels = to_categorical(y_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I9L_4KMC17p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ed74eb8-b5fd-48ca-9c14-a6a6a22a4937"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_dim=input_dim))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(27, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                3021568   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 27)                1755      \n",
            "=================================================================\n",
            "Total params: 3,027,483\n",
            "Trainable params: 3,027,483\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg9JYbA0DbgB"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DuSuRrKERyY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8e49fff-bd46-46be-e3ff-96cd82834a08"
      },
      "source": [
        "history = model.fit(X_train_trans,\n",
        "                    one_hot_train_labels,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(X_test_trans, one_hot_test_labels))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "17/17 [==============================] - 6s 316ms/step - loss: 2.9384 - accuracy: 0.3165 - val_loss: 2.1945 - val_accuracy: 0.5768\n",
            "Epoch 2/20\n",
            "17/17 [==============================] - 5s 284ms/step - loss: 1.9314 - accuracy: 0.6860 - val_loss: 1.8108 - val_accuracy: 0.6404\n",
            "Epoch 3/20\n",
            "17/17 [==============================] - 5s 282ms/step - loss: 1.4042 - accuracy: 0.7719 - val_loss: 1.5518 - val_accuracy: 0.6469\n",
            "Epoch 4/20\n",
            "17/17 [==============================] - 5s 280ms/step - loss: 1.0658 - accuracy: 0.8068 - val_loss: 1.3854 - val_accuracy: 0.6580\n",
            "Epoch 5/20\n",
            "17/17 [==============================] - 5s 282ms/step - loss: 0.7978 - accuracy: 0.8601 - val_loss: 1.2731 - val_accuracy: 0.6869\n",
            "Epoch 6/20\n",
            "17/17 [==============================] - 5s 279ms/step - loss: 0.6170 - accuracy: 0.8965 - val_loss: 1.2091 - val_accuracy: 0.7039\n",
            "Epoch 7/20\n",
            "17/17 [==============================] - 5s 282ms/step - loss: 0.4784 - accuracy: 0.9283 - val_loss: 1.1475 - val_accuracy: 0.7145\n",
            "Epoch 8/20\n",
            "17/17 [==============================] - 5s 283ms/step - loss: 0.3531 - accuracy: 0.9529 - val_loss: 1.1804 - val_accuracy: 0.7069\n",
            "Epoch 9/20\n",
            "17/17 [==============================] - 5s 280ms/step - loss: 0.2728 - accuracy: 0.9613 - val_loss: 1.1744 - val_accuracy: 0.7187\n",
            "Epoch 10/20\n",
            "17/17 [==============================] - 5s 280ms/step - loss: 0.2182 - accuracy: 0.9726 - val_loss: 1.1903 - val_accuracy: 0.7263\n",
            "Epoch 11/20\n",
            "17/17 [==============================] - 5s 278ms/step - loss: 0.1614 - accuracy: 0.9804 - val_loss: 1.1864 - val_accuracy: 0.7204\n",
            "Epoch 12/20\n",
            "17/17 [==============================] - 5s 279ms/step - loss: 0.1241 - accuracy: 0.9883 - val_loss: 1.3033 - val_accuracy: 0.7198\n",
            "Epoch 13/20\n",
            "17/17 [==============================] - 5s 279ms/step - loss: 0.0997 - accuracy: 0.9905 - val_loss: 1.2699 - val_accuracy: 0.7281\n",
            "Epoch 14/20\n",
            "17/17 [==============================] - 5s 277ms/step - loss: 0.0730 - accuracy: 0.9947 - val_loss: 1.3654 - val_accuracy: 0.7216\n",
            "Epoch 15/20\n",
            "17/17 [==============================] - 5s 279ms/step - loss: 0.0583 - accuracy: 0.9956 - val_loss: 1.3921 - val_accuracy: 0.7204\n",
            "Epoch 16/20\n",
            "17/17 [==============================] - 5s 280ms/step - loss: 0.0430 - accuracy: 0.9966 - val_loss: 1.5071 - val_accuracy: 0.7216\n",
            "Epoch 17/20\n",
            "17/17 [==============================] - 5s 282ms/step - loss: 0.0355 - accuracy: 0.9963 - val_loss: 1.5220 - val_accuracy: 0.7110\n",
            "Epoch 18/20\n",
            "17/17 [==============================] - 5s 279ms/step - loss: 0.0301 - accuracy: 0.9964 - val_loss: 1.5754 - val_accuracy: 0.7157\n",
            "Epoch 19/20\n",
            "17/17 [==============================] - 5s 281ms/step - loss: 0.0196 - accuracy: 0.9983 - val_loss: 1.6449 - val_accuracy: 0.7198\n",
            "Epoch 20/20\n",
            "17/17 [==============================] - 5s 276ms/step - loss: 0.0159 - accuracy: 0.9985 - val_loss: 1.7055 - val_accuracy: 0.7151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7lWAWsaisaF"
      },
      "source": [
        "#THe model is overfitting\n",
        "#Il faut changer le modèle afin d'éviter l'overfitting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-_61rdyjQvU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}