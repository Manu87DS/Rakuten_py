{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import unidecode\n",
    "import re\n",
    "\n",
    "#Création fonctions de netoyage de texte\n",
    "import spacy #https://spacy.io/usage  ----> POUR INSTALLER\n",
    "#https://www.stat4decision.com/fr/traitement-langage-naturel-francais-tal-nlp/\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>description</th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3804725264</td>\n",
       "      <td>1263597046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436067568</td>\n",
       "      <td>1008141237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
       "      <td>201115110</td>\n",
       "      <td>938777978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50418756</td>\n",
       "      <td>457047496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Guerre Des Tuques</td>\n",
       "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
       "      <td>278535884</td>\n",
       "      <td>1077757786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Afrique Contemporaine N° 212 Hiver 2004 - Doss...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5862738</td>\n",
       "      <td>393356830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Christof E: Bildungsprozessen Auf Der Spur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91920807</td>\n",
       "      <td>907794536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conquérant Sept Cahier Couverture Polypro 240 ...</td>\n",
       "      <td>CONQUERANT CLASSIQUE Cahier 240 x 320 mm seyès...</td>\n",
       "      <td>344240059</td>\n",
       "      <td>999581347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Puzzle Scooby-Doo Avec Poster 2x35 Pieces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4239126071</td>\n",
       "      <td>1325918866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tente Pliante V3s5-Pro Pvc Blanc - 3 X 4m50 - ...</td>\n",
       "      <td>Tente pliante V3S5 Pro PVC 500 gr/m² - 3 x 4m5...</td>\n",
       "      <td>3793572222</td>\n",
       "      <td>1245644185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Eames Inspired Sxw Chair - Pink - Black</td>\n",
       "      <td>The timeless DSW seat can now be paired with m...</td>\n",
       "      <td>1915836983</td>\n",
       "      <td>1111840281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Fauteuil Chesterfield Brenton 100% Cuir De Buf...</td>\n",
       "      <td>Canapé et fauteuil chesterfield en cuir antiqu...</td>\n",
       "      <td>4127967621</td>\n",
       "      <td>1295816984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Peaceable Kingdom Wheres Bear? The Hide And Fi...</td>\n",
       "      <td>pCan my 2-year-old play a game? Yes Each game ...</td>\n",
       "      <td>3287127001</td>\n",
       "      <td>1204199842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Paire De Voilages Imprimés Fantaisie</td>\n",
       "      <td>Paire de voilages droits fantaisie qui mettra ...</td>\n",
       "      <td>1882164320</td>\n",
       "      <td>1109088140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Matelas Mémoire De Forme 180x200 X 20 Cm Très ...</td>\n",
       "      <td>MATELAS:&lt;br /&gt;Â· Accueil : Ferme .&lt;br /&gt;Â· Sou...</td>\n",
       "      <td>4108914287</td>\n",
       "      <td>1292441752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Zenith Pince Agrafeuse 591 N°10 Coloris Noir</td>\n",
       "      <td>Pince agrafeuse 591 N°10. Capot en ABS. Dispos...</td>\n",
       "      <td>3718150116</td>\n",
       "      <td>1237257586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Walter Scott Oeuvres Complètes Tomes 3456 10 E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3735707499</td>\n",
       "      <td>1239242410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mod Podge Dishwasher Safe Gloss 8oz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2666371748</td>\n",
       "      <td>1156191369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Power Rangers Rouge Force Mystic Figurine Tran...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91015572</td>\n",
       "      <td>857195931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Monde Illustre (Le) N° 3083 Du 20/01/1917 - L'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>570628142</td>\n",
       "      <td>1027257229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          designation  \\\n",
       "0   Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
       "1   Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
       "2   Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
       "3   Peluche Donald - Europe - Disneyland 2000 (Mar...   \n",
       "4                                La Guerre Des Tuques   \n",
       "5   Afrique Contemporaine N° 212 Hiver 2004 - Doss...   \n",
       "6          Christof E: Bildungsprozessen Auf Der Spur   \n",
       "7   Conquérant Sept Cahier Couverture Polypro 240 ...   \n",
       "8           Puzzle Scooby-Doo Avec Poster 2x35 Pieces   \n",
       "9   Tente Pliante V3s5-Pro Pvc Blanc - 3 X 4m50 - ...   \n",
       "10            Eames Inspired Sxw Chair - Pink - Black   \n",
       "11  Fauteuil Chesterfield Brenton 100% Cuir De Buf...   \n",
       "12  Peaceable Kingdom Wheres Bear? The Hide And Fi...   \n",
       "13               Paire De Voilages Imprimés Fantaisie   \n",
       "14  Matelas Mémoire De Forme 180x200 X 20 Cm Très ...   \n",
       "15       Zenith Pince Agrafeuse 591 N°10 Coloris Noir   \n",
       "16  Walter Scott Oeuvres Complètes Tomes 3456 10 E...   \n",
       "17                Mod Podge Dishwasher Safe Gloss 8oz   \n",
       "18  Power Rangers Rouge Force Mystic Figurine Tran...   \n",
       "19  Monde Illustre (Le) N° 3083 Du 20/01/1917 - L'...   \n",
       "\n",
       "                                          description   productid     imageid  \n",
       "0                                                 NaN  3804725264  1263597046  \n",
       "1                                                 NaN   436067568  1008141237  \n",
       "2   PILOT STYLE Touch Pen de marque Speedlink est ...   201115110   938777978  \n",
       "3                                                 NaN    50418756   457047496  \n",
       "4   Luc a des id&eacute;es de grandeur. Il veut or...   278535884  1077757786  \n",
       "5                                                 NaN     5862738   393356830  \n",
       "6                                                 NaN    91920807   907794536  \n",
       "7   CONQUERANT CLASSIQUE Cahier 240 x 320 mm seyès...   344240059   999581347  \n",
       "8                                                 NaN  4239126071  1325918866  \n",
       "9   Tente pliante V3S5 Pro PVC 500 gr/m² - 3 x 4m5...  3793572222  1245644185  \n",
       "10  The timeless DSW seat can now be paired with m...  1915836983  1111840281  \n",
       "11  Canapé et fauteuil chesterfield en cuir antiqu...  4127967621  1295816984  \n",
       "12  pCan my 2-year-old play a game? Yes Each game ...  3287127001  1204199842  \n",
       "13  Paire de voilages droits fantaisie qui mettra ...  1882164320  1109088140  \n",
       "14  MATELAS:<br />Â· Accueil : Ferme .<br />Â· Sou...  4108914287  1292441752  \n",
       "15  Pince agrafeuse 591 N°10. Capot en ABS. Dispos...  3718150116  1237257586  \n",
       "16                                                NaN  3735707499  1239242410  \n",
       "17                                                NaN  2666371748  1156191369  \n",
       "18                                                NaN    91015572   857195931  \n",
       "19                                                NaN   570628142  1027257229  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importer les données texte\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "df_X = pd.read_csv(r'C:\\Users\\Edgar\\Documents\\Rakuten\\X_train_update.csv',index_col =0)\n",
    "df_X.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num lignes totale: 84916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     Olivia: Personalisiertes Notizbuch / 150 Seite...\n",
       "1     Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...\n",
       "2     Grand Stylet Ergonomique Bleu Gamepad Nintendo...\n",
       "3     Peluche Donald - Europe - Disneyland 2000 (Mar...\n",
       "4     La Guerre Des Tuques Luc a des id&eacute;es de...\n",
       "5     Afrique Contemporaine N° 212 Hiver 2004 - Doss...\n",
       "6        Christof E: Bildungsprozessen Auf Der Spur nan\n",
       "7     Conquérant Sept Cahier Couverture Polypro 240 ...\n",
       "8         Puzzle Scooby-Doo Avec Poster 2x35 Pieces nan\n",
       "9     Tente Pliante V3s5-Pro Pvc Blanc - 3 X 4m50 - ...\n",
       "10    Eames Inspired Sxw Chair - Pink - Black The ti...\n",
       "11    Fauteuil Chesterfield Brenton 100% Cuir De Buf...\n",
       "12    Peaceable Kingdom Wheres Bear? The Hide And Fi...\n",
       "13    Paire De Voilages Imprimés Fantaisie Paire de ...\n",
       "14    Matelas Mémoire De Forme 180x200 X 20 Cm Très ...\n",
       "15    Zenith Pince Agrafeuse 591 N°10 Coloris Noir P...\n",
       "16    Walter Scott Oeuvres Complètes Tomes 3456 10 E...\n",
       "17              Mod Podge Dishwasher Safe Gloss 8oz nan\n",
       "18    Power Rangers Rouge Force Mystic Figurine Tran...\n",
       "19    Monde Illustre (Le) N° 3083 Du 20/01/1917 - L'...\n",
       "dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merger les colones texte en une seule\n",
    "X = df_X.designation.astype(str) + ' ' + df_X.description.astype(str)\n",
    "\n",
    "#Numero de lignes du texte\n",
    "size_X = X.size\n",
    "print('Num lignes totale:', size_X)\n",
    "\n",
    "X.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokeniser(sentence,language): #Tokenisation par phrases\n",
    "    \n",
    "    langue = {'french':'fr_core_news_sm',\n",
    "          'german':'de_core_news_sm',\n",
    "          'english':'en_core_web_sm'}\n",
    "    \n",
    "    nlp = spacy.load(langue[language])\n",
    "    # Tokeniser la phrase\n",
    "    tokens = nlp(sentence)\n",
    "    # Retourner le texte coupé par mots(token)\n",
    "    return [token for token in tokens]\n",
    "\n",
    "def language_(language):\n",
    "    langue = {'fr':'french',\n",
    "             'de':'german',\n",
    "             'en':'english'}\n",
    "    return langue[language]\n",
    "\n",
    "def stop_words(sentence,language): #Enleve stop words per phrase\n",
    "    clean_words = ''\n",
    "    stop_words =stopwords.words(language)\n",
    "    tokens = tokeniser(sentence,language)\n",
    "    for token in tokens:\n",
    "        if token.text not in stop_words:\n",
    "            clean_words += token.text + ' '\n",
    "    return clean_words\n",
    "\n",
    "def number_unique_words(text_series): #count unique words in Series\n",
    "    words = []\n",
    "    for sentence in text_series.str.split():\n",
    "        for word in sentence:\n",
    "            words.append(word)\n",
    "            \n",
    "    return len(list(set(words)))\n",
    "\n",
    "def remove_accents(sentece,language): #removes accents\n",
    "    #language is not used in this function, but needs to be added on the definition as the rest\n",
    "    try:\n",
    "        text = unidecode.unidecode(sentece)\n",
    "    except:\n",
    "        pass\n",
    "    return text\n",
    "\n",
    "def steem(sentence,language): #Steeming\n",
    "    steemed = ''\n",
    "    tokens = tokeniser(sentence,language)\n",
    "    stemmer = SnowballStemmer(language=language)\n",
    "    \n",
    "    for token in tokens:\n",
    "        steemed += stemmer.stem(token.text) +' '\n",
    "    return steemed\n",
    "\n",
    "def lemma(sentence,language): #Lemmatizer\n",
    "    lemma = ''\n",
    "    tokens = tokeniser(sentence,language)\n",
    "    \n",
    "    for token in tokens:\n",
    "        lemma += token.lemma_ + ' '\n",
    "    return lemma\n",
    "\n",
    "def no_num(sentence,language): #delete numbers\n",
    "    #language is not used in this function, but needs to be added on the definition as the rest\n",
    "    return ''.join([word for word in sentence if not word.isdigit()])\n",
    "\n",
    "def no_special(sentence,language): #delete special characters\n",
    "    #language is not used in this function, but needs to be added on the definition as the rest\n",
    "    return re.sub(r\"[^a-zA-Z0-9]+\", ' ', sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le traitement de text est très long et des fois on lance le code et après plusieurs heures de tourner on ne sait pas si le code a bientôt fini ou pas\n",
    "# Ce code divise le dataframe en batchs afin de voir l'avancement du traitement à chaque fin de batch\n",
    "\n",
    "def treat_text(text_series,text_treat_funct,language,batch,old_treatments=''):\n",
    "    \n",
    "    treatments = '_' + text_treat_funct.__name__ + '_' + language\n",
    "    language = language_(language)\n",
    "    \n",
    "    print('************************************************')\n",
    "    print('')\n",
    "    print(text_treat_funct.__name__.upper(),language.upper())\n",
    "    print(\"Treatment Start Time =\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "    print(\"Number of unique words at start =\", number_unique_words(text_series))\n",
    "    #print('Type of function:', text_treat_funct.__name__)\n",
    "    #print('Treatment language choosen:', language)\n",
    "    print('Number of batch:', batch)\n",
    "    \n",
    "    size = text_series.size\n",
    "    treated_text = pd.Series()\n",
    "    text = text_series.str.lower()\n",
    "    \n",
    "    #treat batches\n",
    "    for i in range(batch):\n",
    "        treated_batch = text[int(size/batch) * i:int(size/batch) * (i + 1)].apply(lambda cell: text_treat_funct(cell,language))\n",
    "        treated_text = pd.concat([treated_text,treated_batch])\n",
    "        \n",
    "        print('Treatment Batch', i, 'from', batch ,'; Time =', datetime.now().strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "    #tret last batch\n",
    "    treated_batch = text[int(size/batch) * (i + 1):size].apply(lambda cell: text_treat_funct(cell,language))\n",
    "    treated_text = pd.concat([treated_text,treated_batch])\n",
    "    \n",
    "    treated_text.to_csv('X_train' + old_treatments + treatments + '.csv') \n",
    "    \n",
    "    print(\"Number of unique words at end =\", number_unique_words(treated_text))\n",
    "    print('')\n",
    "    \n",
    "    return treated_text, old_treatments + treatments\n",
    "\n",
    "#X_test = X[:23]\n",
    "#treat_text(X_test,no_special,'french',7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************\n",
      "\n",
      "LEMMA FRENCH\n",
      "Treatment Start Time = 09:00:55\n",
      "Number of unique words at start = 407222\n",
      "Number of batch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-209-f0dd036dfd0b>:19: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  treated_text = pd.Series()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment Batch 0 from 20 ; Time = 10:02:46\n",
      "Treatment Batch 1 from 20 ; Time = 11:04:47\n",
      "Treatment Batch 2 from 20 ; Time = 12:06:51\n",
      "Treatment Batch 3 from 20 ; Time = 13:08:56\n",
      "Treatment Batch 4 from 20 ; Time = 14:11:09\n",
      "Treatment Batch 5 from 20 ; Time = 15:13:28\n",
      "Treatment Batch 6 from 20 ; Time = 16:15:34\n",
      "Treatment Batch 7 from 20 ; Time = 17:17:51\n",
      "Treatment Batch 8 from 20 ; Time = 18:20:13\n",
      "Treatment Batch 9 from 20 ; Time = 19:22:40\n",
      "Treatment Batch 10 from 20 ; Time = 20:25:16\n",
      "Treatment Batch 11 from 20 ; Time = 21:28:05\n",
      "Treatment Batch 12 from 20 ; Time = 22:31:01\n",
      "Treatment Batch 13 from 20 ; Time = 23:33:44\n"
     ]
    }
   ],
   "source": [
    "#on va creer differents fichiers X_train avec des differents traitements. Ça nous permettra de comprarer les résultats des modèlisations en fonction du traitement\n",
    "function_list = [stop_words, remove_accents, steem, lemma, no_num, no_special]\n",
    "langues = ['french','english','german']\n",
    "\n",
    "\n",
    "batch = 20\n",
    "\n",
    "\n",
    "X_treated, treatments = treat_text(X,lemma,'fr',batch)\n",
    "X_treated, treatments = treat_text(X_treated,lemma,'en',batch,treatments)\n",
    "X_treated, treatments = treat_text(X_treated,lemma,'de',batch,treatments)\n",
    "X_treated, treatments = treat_text(X_test,stop_words,'fr',batch)\n",
    "X_treated, treatments = treat_text(X_treated,stop_words,'en',batch,treatments)\n",
    "X_treated, treatments = treat_text(X_treated,stop_words,'de',batch,treatments)\n",
    "X_treated, treatments = treat_text(X_test,remove_accents,'fr',batch)\n",
    "X_treated, treatments = treat_text(X_treated,no_num,'fr',batch,treatments)\n",
    "X_treated, treatments = treat_text(X_treated,no_special,'fr',batch,treatments)\n",
    "\n",
    "X_treated, treatments = treat_text(X_treated,steem,'fr',batch,treatments)\n",
    "X_treated, treatments = treat_text(X_treated,steem,'en',batch,treatments)\n",
    "X_treated, treatments = treat_text(X_treated,steem,'de',batch,treatments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
